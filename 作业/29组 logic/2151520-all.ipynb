{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the training and test datasets\n",
    "train_data_path = './processed_train.csv'\n",
    "test_data_path = './processed_test.csv'\n",
    "\n",
    "train_df = pd.read_csv(train_data_path)\n",
    "test_df = pd.read_csv(test_data_path)\n",
    "\n",
    "# Display the first few rows of the datasets for initial inspection\n",
    "train_df.head(), test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing values and data types in the datasets\n",
    "missing_values_train = train_df.isnull().sum()\n",
    "missing_values_test = test_df.isnull().sum()\n",
    "data_types_train = train_df.dtypes\n",
    "data_types_test = test_df.dtypes\n",
    "\n",
    "missing_values_train, missing_values_test, data_types_train, data_types_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "corr_matrix = train_df.corr()\n",
    "\n",
    "# Plotting the correlation heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title(\"Correlation Matrix of Features\")\n",
    "plt.show()\n",
    "\n",
    "# Displaying the correlation of each feature with the target variable 'Transported'\n",
    "corr_with_target = corr_matrix['Transported'].sort_values(ascending=False)\n",
    "corr_with_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Splitting the training data into features and target variable\n",
    "X_train = train_df.drop('Transported', axis=1)\n",
    "y_train = train_df['Transported']\n",
    "\n",
    "# Logistic Regression Model\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Decision Tree Classifier Model\n",
    "dec_tree = DecisionTreeClassifier()\n",
    "dec_tree.fit(X_train, y_train)\n",
    "\n",
    "# Preparing the test data (excluding the target variable)\n",
    "X_test = test_df.drop('Transported', axis=1, errors='ignore')  # 'errors=ignore' in case 'Transported' is not in test data\n",
    "\n",
    "# Predictions\n",
    "log_reg_pred = log_reg.predict(X_test)\n",
    "dec_tree_pred = dec_tree.predict(X_test)\n",
    "\n",
    "# Since we don't have the true labels for the test set, we'll evaluate on a split of the training set\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train, y_train, test_size=0.3, random_state=42)\n",
    "\n",
    "# Evaluate on the validation set\n",
    "log_reg_val_pred = log_reg.predict(X_val_split)\n",
    "dec_tree_val_pred = dec_tree.predict(X_val_split)\n",
    "\n",
    "# Evaluating the performance\n",
    "log_reg_accuracy = accuracy_score(y_val_split, log_reg_val_pred)\n",
    "dec_tree_accuracy = accuracy_score(y_val_split, dec_tree_val_pred)\n",
    "\n",
    "log_reg_report = classification_report(y_val_split, log_reg_val_pred)\n",
    "dec_tree_report = classification_report(y_val_split, dec_tree_val_pred)\n",
    "\n",
    "# log_reg_accuracy, dec_tree_accuracy, log_reg_report, dec_tree_report\n",
    "print(\"Logistic Regression Model Evaluation:\")\n",
    "print(\"--------------------------------------\")\n",
    "print(f\"Accuracy: {log_reg_accuracy:.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(log_reg_report)\n",
    "\n",
    "print(\"\\nDecision Tree Classifier Model Evaluation:\")\n",
    "print(\"-------------------------------------------\")\n",
    "print(f\"Accuracy: {dec_tree_accuracy:.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(dec_tree_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting features with higher correlation\n",
    "selected_features = ['CryoSleep', 'RoomService', 'Spa', 'VRDeck']\n",
    "\n",
    "# Creating new feature sets based on selected features\n",
    "X_train_selected = X_train[selected_features]\n",
    "X_val_split_selected = X_val_split[selected_features]\n",
    "\n",
    "# Logistic Regression Model with selected features\n",
    "log_reg_selected = LogisticRegression()\n",
    "log_reg_selected.fit(X_train_selected, y_train)\n",
    "\n",
    "# Decision Tree Classifier Model with selected features\n",
    "dec_tree_selected = DecisionTreeClassifier()\n",
    "dec_tree_selected.fit(X_train_selected, y_train)\n",
    "\n",
    "# Evaluating the performance on the validation set with selected features\n",
    "log_reg_val_pred_selected = log_reg_selected.predict(X_val_split_selected)\n",
    "dec_tree_val_pred_selected = dec_tree_selected.predict(X_val_split_selected)\n",
    "\n",
    "# Calculating accuracy\n",
    "log_reg_accuracy_selected = accuracy_score(y_val_split, log_reg_val_pred_selected)\n",
    "dec_tree_accuracy_selected = accuracy_score(y_val_split, dec_tree_val_pred_selected)\n",
    "\n",
    "log_reg_accuracy_selected, dec_tree_accuracy_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Creating models for different classification methods\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Support Vector Machine\": SVC(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Gaussian Naive Bayes\": GaussianNB()\n",
    "}\n",
    "\n",
    "# Dictionary to store the accuracy of each model\n",
    "accuracy_scores = {}\n",
    "\n",
    "# Splitting the training data into features and target variable\n",
    "X_train = train_df.drop('Transported', axis=1)\n",
    "y_train = train_df['Transported']\n",
    "\n",
    "# Since we don't have the true labels for the test set, we'll evaluate on a split of the training set\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train, y_train, test_size=0.3, random_state=42)\n",
    "\n",
    "# Training and evaluating each model\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    val_pred = model.predict(X_val_split)\n",
    "    accuracy = accuracy_score(y_val_split, val_pred)\n",
    "    accuracy_scores[name] = accuracy\n",
    "    print(f\"{name} Model Evaluation:\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(\"-------------------------------------\")\n",
    "\n",
    "# Comparing the results\n",
    "accuracy_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, f1_score\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# 手写逻辑回归\n",
    "class LogisticRegression:\n",
    "    def __init__(self, learning_rate=0.01, n_iterations=1000, l2_reg=0):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        self.l2_reg = l2_reg  # L2 regularization term\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.losses = []  # To record the loss during training\n",
    "        self.accuracies = []  # To record the accuracy during training\n",
    "\n",
    "    def _sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def _compute_loss(self, y, predictions):\n",
    "        # Regularization term\n",
    "        reg_term = (self.l2_reg / 2) * np.sum(np.square(self.weights))\n",
    "        return -np.mean(y * np.log(predictions) + (1 - y) * np.log(1 - predictions)) + reg_term\n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        # Gradient Descent\n",
    "        for _ in range(self.n_iterations):\n",
    "            model = np.dot(X, self.weights) + self.bias\n",
    "            predictions = self._sigmoid(model)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = self._compute_loss(y, predictions)\n",
    "            self.losses.append(loss)\n",
    "\n",
    "            # Compute gradients\n",
    "            dw = (1 / n_samples) * np.dot(X.T, (predictions - y)) + (self.l2_reg * self.weights)\n",
    "            db = (1 / n_samples) * np.sum(predictions - y)\n",
    "\n",
    "            # Update parameters\n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "\n",
    "            # Validation accuracy\n",
    "            if X_val is not None and y_val is not None:\n",
    "                val_pred = self.predict(X_val)\n",
    "                val_accuracy = accuracy_score(y_val, val_pred)\n",
    "                self.accuracies.append(val_accuracy)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        model = np.dot(X, self.weights) + self.bias\n",
    "        predictions = self._sigmoid(model)\n",
    "        return predictions\n",
    "\n",
    "    def predict(self, X):\n",
    "        probabilities = self.predict_proba(X)\n",
    "        return np.array([1 if i > 0.5 else 0 for i in probabilities])\n",
    "\n",
    "    def plot_losses(self):\n",
    "        plt.plot(self.losses, label=\"Loss\")\n",
    "        plt.title(\"Loss during Training\")\n",
    "        plt.xlabel(\"Iteration\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_accuracies(self):\n",
    "        plt.plot(self.accuracies, label=\"Accuracy\")\n",
    "        plt.title(\"Accuracy during Training\")\n",
    "        plt.xlabel(\"Iteration\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_probability_distribution(self, X, y):\n",
    "        probabilities = self.predict_proba(X)\n",
    "        plt.hist(probabilities, bins=10, alpha=0.7, label='Predicted Probabilities')\n",
    "        plt.title(\"Distribution of Predicted Probabilities\")\n",
    "        plt.xlabel(\"Probability\")\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_confusion_matrix(self, X, y):\n",
    "        predictions = self.predict(X)\n",
    "        cm = confusion_matrix(y, predictions)\n",
    "        sns.heatmap(cm, annot=True, fmt='g', cmap='Blues')\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"True\")\n",
    "        plt.show()\n",
    "\n",
    "# Creating an instance of the enhanced Logistic Regression model\n",
    "lr_model = LogisticRegression(learning_rate=0.01, n_iterations=1000, l2_reg=0.1)\n",
    "\n",
    "# Training the model with validation data for accuracy tracking\n",
    "lr_model.fit(X_train_split.values, y_train_split.values, X_val_split.values, y_val_split.values)\n",
    "\n",
    "# Plotting the training losses and accuracies\n",
    "lr_model.plot_losses()\n",
    "lr_model.plot_accuracies()\n",
    "\n",
    "# Plotting the probability distribution and confusion matrix\n",
    "lr_model.plot_probability_distribution(X_val_split.values, y_val_split.values)\n",
    "lr_model.plot_confusion_matrix(X_val_split.values, y_val_split.values)\n",
    "\n",
    "# Predicting and evaluating on the validation set\n",
    "lr_predictions = lr_model.predict(X_val_split.values)\n",
    "lr_accuracy = accuracy_score(y_val_split, lr_predictions)\n",
    "lr_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 手写决策树 这段代码的运行可能需要 3 - 5 min 的时间\n",
    "class Question:\n",
    "    \"\"\"A Question is used to partition a dataset. This class just records a 'column number' (e.g., 0 for the first column) and a 'column value' (e.g., Green). The 'match' method is used to compare the feature value in an example to the feature value stored in the question.\"\"\"\n",
    "    def __init__(self, column, value):\n",
    "        self.column = column\n",
    "        self.value = value\n",
    "\n",
    "    def match(self, example):\n",
    "        # Compare the feature value in an example to the feature value in this question.\n",
    "        val = example[self.column]\n",
    "        if isinstance(val, int) or isinstance(val, float):\n",
    "            return val >= self.value\n",
    "        else:\n",
    "            return val == self.value\n",
    "\n",
    "    def __repr__(self):\n",
    "        # This is just a helper method to print the question in a readable format.\n",
    "        condition = \"==\"\n",
    "        if isinstance(self.value, int) or isinstance(self.value, float):\n",
    "            condition = \">=\"\n",
    "        return f\"Is {self.column} {condition} {str(self.value)}?\"\n",
    "\n",
    "class DecisionNode:\n",
    "    \"\"\"A Decision Node asks a question. This holds a reference to the question, and to the two child nodes.\"\"\"\n",
    "    def __init__(self, question, true_branch, false_branch):\n",
    "        self.question = question\n",
    "        self.true_branch = true_branch\n",
    "        self.false_branch = false_branch\n",
    "\n",
    "class Leaf:\n",
    "    \"\"\"A Leaf node classifies data. This holds a dictionary of class (e.g., \"Apple\") -> number of times it appears in the rows from the training data that reach this leaf.\"\"\"\n",
    "    def __init__(self, rows):\n",
    "        self.predictions = self.class_counts(rows)\n",
    "\n",
    "    @staticmethod\n",
    "    def class_counts(rows):\n",
    "        \"\"\"Counts the number of each type of example in a dataset.\"\"\"\n",
    "        counts = {}  # a dictionary of label -> count.\n",
    "        for row in rows:\n",
    "            # in our dataset format, the label is always the last column\n",
    "            label = row[-1]\n",
    "            if label not in counts:\n",
    "                counts[label] = 0\n",
    "            counts[label] += 1\n",
    "        return counts\n",
    "\n",
    "class DecisionTreeClassifierFromScratch:\n",
    "    def __init__(self, max_depth=5):\n",
    "        self.max_depth = max_depth\n",
    "        self.root = None\n",
    "\n",
    "    @staticmethod\n",
    "    def gini(rows):\n",
    "        \"\"\"Calculate the Gini Impurity for a list of rows.\"\"\"\n",
    "        counts = Leaf.class_counts(rows)\n",
    "        impurity = 1\n",
    "        for lbl in counts:\n",
    "            prob_of_lbl = counts[lbl] / float(len(rows))\n",
    "            impurity -= prob_of_lbl**2\n",
    "        return impurity\n",
    "\n",
    "    @staticmethod\n",
    "    def info_gain(left, right, current_uncertainty):\n",
    "        \"\"\"Information Gain. The uncertainty of the starting node, minus the weighted impurity of two child nodes.\"\"\"\n",
    "        p = float(len(left)) / (len(left) + len(right))\n",
    "        return current_uncertainty - p * DecisionTreeClassifierFromScratch.gini(left) - (1 - p) * DecisionTreeClassifierFromScratch.gini(right)\n",
    "\n",
    "    def find_best_split(self, rows):\n",
    "        \"\"\"Find the best question to ask by iterating over every feature / value and calculating the information gain.\"\"\"\n",
    "        best_gain = 0  # keep track of the best information gain\n",
    "        best_question = None  # keep track of the feature / value that produced it\n",
    "        current_uncertainty = self.gini(rows)\n",
    "        n_features = len(rows[0]) - 1  # number of columns\n",
    "\n",
    "        for col in range(n_features):  # for each feature\n",
    "            print(col)\n",
    "            values = set([row[col] for row in rows])  # unique values in the column\n",
    "\n",
    "            for val in values:  # for each value\n",
    "                question = Question(col, val)\n",
    "\n",
    "                # try splitting the dataset\n",
    "                true_rows, false_rows = self.partition(rows, question)\n",
    "\n",
    "                # Skip this split if it doesn't divide the dataset.\n",
    "                if len(true_rows) == 0 or len(false_rows) == 0:\n",
    "                    continue\n",
    "\n",
    "                # Calculate the information gain from this split\n",
    "                gain = self.info_gain(true_rows, false_rows, current_uncertainty)\n",
    "\n",
    "                if gain >= best_gain:\n",
    "                    best_gain, best_question = gain, question\n",
    "\n",
    "        return best_gain, best_question\n",
    "\n",
    "    @staticmethod\n",
    "    def partition(rows, question):\n",
    "        \"\"\"Partitions a dataset. For each row in the dataset, check if it matches the question. If so, add it to 'true rows', otherwise, add it to 'false rows'.\"\"\"\n",
    "        true_rows, false_rows = [], []\n",
    "        for row in rows:\n",
    "            if question.match(row):\n",
    "                true_rows.append(row)\n",
    "            else:\n",
    "                false_rows.append(row)\n",
    "        return true_rows, false_rows\n",
    "\n",
    "    def build_tree(self, rows, depth=0):\n",
    "        \"\"\"Builds the tree.\"\"\"\n",
    "        # Checking if the depth limit is reached\n",
    "        if depth >= self.max_depth:\n",
    "            return Leaf(rows)\n",
    "\n",
    "        gain, question = self.find_best_split(rows)\n",
    "\n",
    "        # Base case: no further info gain\n",
    "        if gain == 0:\n",
    "            return Leaf(rows)\n",
    "\n",
    "        true_rows, false_rows = self.partition(rows, question)\n",
    "\n",
    "        # Recursively build the true branch\n",
    "        true_branch = self.build_tree(true_rows, depth + 1)\n",
    "\n",
    "        # Recursively build the false branch\n",
    "        false_branch = self.build_tree(false_rows, depth + 1)\n",
    "\n",
    "        # Return a Question node\n",
    "        return DecisionNode(question, true_branch, false_branch)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fits the model to the data.\"\"\"\n",
    "        rows = np.c_[X, y]\n",
    "        self.root = self.build_tree(rows)\n",
    "\n",
    "    def predict_row(self, node, row):\n",
    "        \"\"\"Predicts the label for a single row of data.\"\"\"\n",
    "        if isinstance(node, Leaf):\n",
    "            return max(node.predictions, key=node.predictions.get)\n",
    "\n",
    "        if node.question.match(row):\n",
    "            return self.predict_row(node.true_branch, row)\n",
    "        else:\n",
    "            return self.predict_row(node.false_branch, row)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predicts labels for each row in X.\"\"\"\n",
    "        return [self.predict_row(self.root, row) for row in X]\n",
    "\n",
    "# Now, we can create an instance with a specified max_depth\n",
    "dtc_model = DecisionTreeClassifierFromScratch(max_depth=5)\n",
    "\n",
    "# Training the model\n",
    "dtc_model.fit(X_train_split.values, y_train_split.values)\n",
    "\n",
    "# Predicting on the validation set\n",
    "dtc_predictions = dtc_model.predict(X_val_split.values)\n",
    "\n",
    "# Calculating the accuracy\n",
    "dtc_accuracy = accuracy_score(y_val_split, dtc_predictions)\n",
    "dtc_accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
